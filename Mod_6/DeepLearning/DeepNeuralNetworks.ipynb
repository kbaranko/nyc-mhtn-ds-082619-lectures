{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Off\n",
    "\n",
    "How does sklearn utilize numpy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build a Deep Neural Network with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building steps:\n",
    "\n",
    "1. Specify Architecture\n",
    "\n",
    "2. Compile\n",
    "\n",
    "3. Fit \n",
    "\n",
    "4. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the model\n",
    "model = Sequential()\n",
    "#create the input layer\n",
    "model.add(Dense(100, activation='relu', input_shape = (n_cols,)))\n",
    "#add one hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "#add the final layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling a model \n",
    "\n",
    "- Specify the optimizer\n",
    "    - Many options and mathematically complex\n",
    "    - “Adam” is usually a good choice \n",
    "- Loss function\n",
    "    - “mean_squared_error” common for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model\n",
    "\n",
    "- Applying backpropagation and gradient descent with your data to update the weights\n",
    "- Scaling data before fi!ing can ease optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/learn-co-students/nyc-mhtn-ds-042219-lectures/master/Module_4/kc_feat_engineering_project_revamp/kc_housing_data_for_feat_engineering_lab.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>yr_old</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>since_sold</th>\n",
       "      <th>price_log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7129300520</th>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>62</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>12.309982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414100192</th>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>66</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>13.195614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631500400</th>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>84</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>12.100712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487200875</th>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>52</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>13.311329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954400510</th>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>30</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>13.142166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "id                                                                             \n",
       "7129300520  2014-10-13  221900.0         3       1.00         1180      5650   \n",
       "6414100192  2014-12-09  538000.0         3       2.25         2570      7242   \n",
       "5631500400  2015-02-25  180000.0         2       1.00          770     10000   \n",
       "2487200875  2014-12-09  604000.0         4       3.00         1960      5000   \n",
       "1954400510  2015-02-18  510000.0         3       2.00         1680      8080   \n",
       "\n",
       "            floors  waterfront  view  condition    ...      yr_renovated  \\\n",
       "id                                                 ...                     \n",
       "7129300520     1.0           0     0          3    ...                 0   \n",
       "6414100192     2.0           0     0          3    ...              1991   \n",
       "5631500400     1.0           0     0          3    ...                 0   \n",
       "2487200875     1.0           0     0          5    ...                 0   \n",
       "1954400510     1.0           0     0          3    ...                 0   \n",
       "\n",
       "            zipcode      lat     long  sqft_living15  sqft_lot15  yr_old  \\\n",
       "id                                                                         \n",
       "7129300520    98178  47.5112 -122.257           1340        5650      62   \n",
       "6414100192    98125  47.7210 -122.319           1690        7639      66   \n",
       "5631500400    98028  47.7379 -122.233           2720        8062      84   \n",
       "2487200875    98136  47.5208 -122.393           1360        5000      52   \n",
       "1954400510    98074  47.6168 -122.045           1800        7503      30   \n",
       "\n",
       "            year_sold  since_sold  price_log  \n",
       "id                                            \n",
       "7129300520       2014           3  12.309982  \n",
       "6414100192       2014           3  13.195614  \n",
       "5631500400       2015           2  12.100712  \n",
       "2487200875       2014           3  13.311329  \n",
       "1954400510       2015           2  13.142166  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
    "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15', 'yr_old', 'since_sold',\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Store the number of columns in the predictors data to `n_cols`. This has been done for you.\n",
    "- Start by creating a `Sequential` model called `model`.\n",
    "- Use the `.add()` method on `model` to add a `Dense` layer.\n",
    "- Add 50 units, specify `activation='relu'`, and the `input_shape` parameter to be the tuple `(n_cols,)` which means it has `n_cols` items in each row of data, and any number of rows of data are acceptable as inputs.\n",
    "- Add another `Dense` layer. This should have 32 units and a 'relu' activation.\n",
    "- Finally, add an output layer, which is a `Dense` layer with a single node. Don't use any activation function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = len(features)\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compile the model using `model.compile()`. Your `optimizer` should be `'adam'` and the `loss` should be `'mean_squared_error'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the `model`. Remember that the first argument is the predictive features (`predictors`), and the data to be predicted (`target`) is the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "21600/21600 [==============================] - 2s 75us/step - loss: 141241996289.5170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1053a4f60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n",
    "\n",
    "\n",
    "- ‘categorical_crossentropy’ loss function Similar to log loss: Lower is be!er\n",
    "- Add metrics = [‘accuracy’] to compile step for easy-to- understand diagnostics\n",
    "- Output layer has separate node for each possible outcome, and uses ‘so\"max’ activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>youngin</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass   Age  SibSp  Parch     Fare  youngin  male  Q  \\\n",
       "PassengerId                                                                    \n",
       "1                   0       3  22.0      1      0   7.2500        0     1  0   \n",
       "2                   1       1  38.0      1      0  71.2833        0     0  0   \n",
       "3                   1       3  26.0      0      0   7.9250        0     0  0   \n",
       "4                   1       1  35.0      1      0  53.1000        0     0  0   \n",
       "5                   0       3  35.0      0      0   8.0500        0     1  0   \n",
       "\n",
       "             S  \n",
       "PassengerId     \n",
       "1            1  \n",
       "2            0  \n",
       "3            1  \n",
       "4            1  \n",
       "5            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/learn-co-students/nyc-mhtn-ds-042219-lectures/master/Module_4/cleaned_titanic.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.drop(columns=['Survived'])\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert `df.Survived` to a categorical variable using the `to_categorical()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `train_test_split` from `sklearn.model_selection`\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify a `Sequential` model called `model`.\n",
    "- Add a `Dense` layer with 32 nodes. Use `'relu'` as the `activation` and `(n_cols,)` as the `input_shape`.\n",
    "- Add the `Dense` output layer. Because there are two outcomes, it should have 2 units, and because it is a classification model, the `activation` should be `'softmax'`.\n",
    "- Compile the model, using `'sgd'` as the `optimizer`, `'categorical_crossentropy'` as the loss function, and `metrics=['accuracy']` to see the accuracy (what fraction of predictions were correct) at the end of each epoch.\n",
    "- Fit the model using the `X_train` and the `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "711/711 [==============================] - 0s 304us/step - loss: 3.6460 - acc: 0.5809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb243eb0f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#sgd = stochastic gradient descent\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving, reloading and using your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'my_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3080bf7350d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_file.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_predict_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprobability_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'my_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model.save('model_file.h5')\n",
    "my_model = load_model('my_model.h5')\n",
    "predictions = my_model.predict(data_to_predict_with)\n",
    "probability_true = predictions[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create your predictions using the model's `.predict()` method on `X_test`.\n",
    "- Use NumPy indexing to find the column corresponding to predicted probabilities of survival being True. This is the second column (index `1`) of `predictions`. Store the result in `predicted_prob_true` and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.8297512e-04 1.0000000e+00 4.1366947e-01 1.4383215e-03 1.0000000e+00\n",
      " 4.2490708e-04 1.0097281e-02 5.4348866e-03 1.0000000e+00 1.0000000e+00\n",
      " 9.9999225e-01 6.6690743e-02 3.1139700e-07 4.8288694e-03 4.5042078e-04\n",
      " 7.2296840e-01 1.0000000e+00 1.0611756e-03 9.9997354e-01 1.5028428e-03\n",
      " 1.0000000e+00 1.0000000e+00 5.1995212e-06 3.1562802e-01 1.5809595e-03\n",
      " 6.1334375e-02 1.5265548e-04 1.0051708e-03 9.9999297e-01 2.5152268e-03\n",
      " 9.9999297e-01 8.7763963e-04 1.5809595e-03 9.9996197e-01 8.1321970e-02\n",
      " 1.0000000e+00 9.9998403e-01 1.0000000e+00 1.7278912e-03 1.5809595e-03\n",
      " 7.9545175e-04 6.8348809e-04 2.8781895e-02 7.5330870e-04 6.4636141e-01\n",
      " 5.1850140e-01 9.9369472e-01 1.1380878e-03 3.6123619e-04 1.0000000e+00\n",
      " 9.9999988e-01 5.1356484e-03 2.8992030e-03 1.2656149e-03 9.9980706e-01\n",
      " 9.9994719e-01 6.5992763e-06 1.3959563e-05 7.9409383e-02 6.3221279e-04\n",
      " 3.0874587e-03 2.0255984e-03 1.0000000e+00 9.5548958e-02 1.5524996e-03\n",
      " 3.6208355e-01 5.1895961e-07 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 4.2539407e-03 1.0000000e+00 5.7849020e-02 6.8621297e-04 3.3684779e-04\n",
      " 9.8164938e-03 1.0081870e-02 3.9081762e-05 9.9911326e-01 9.9882394e-01\n",
      " 2.0441903e-06 9.9853647e-01 4.3415859e-01 8.7763963e-04 9.6444860e-03\n",
      " 1.0071443e-03 5.1880988e-06 2.8781895e-02 8.6049869e-04 1.5809595e-03\n",
      " 1.5704118e-04 5.3569125e-03 2.4236527e-03 8.2894847e-05 1.0000000e+00\n",
      " 8.9225781e-01 1.5028428e-03 1.3229050e-04 9.9815530e-01 1.0071443e-03\n",
      " 8.0572505e-04 1.0000000e+00 9.9999976e-01 1.2809988e-04 3.8280351e-08\n",
      " 4.2886218e-06 4.8626261e-04 1.0000000e+00 2.1134675e-03 5.0419709e-03\n",
      " 1.4800710e-02 1.0000000e+00 1.0000000e+00 1.0000000e+00 7.1805029e-04\n",
      " 7.4457433e-03 9.2974255e-07 8.5071617e-05 7.4327912e-04 9.8215854e-01\n",
      " 1.0000000e+00 1.0000000e+00 9.0835840e-07 4.0559977e-02 1.0000000e+00\n",
      " 1.0000000e+00 3.1562802e-01 1.0000000e+00 2.4718517e-03 5.5388309e-06\n",
      " 7.7821803e-04 2.0168424e-01 1.0000000e+00 1.0597121e-03 6.4752169e-04\n",
      " 8.7345701e-01 1.5180935e-04 1.5375892e-02 9.5582509e-01 9.9971682e-01\n",
      " 2.7475578e-03 1.5028428e-03 2.4993608e-03 3.1370836e-01 1.0000000e+00\n",
      " 1.0000000e+00 1.1703988e-08 1.0000000e+00 1.4443493e-03 1.0000000e+00\n",
      " 1.3177081e-03 9.7340685e-01 9.9999857e-01 1.0000000e+00 6.5923007e-03\n",
      " 1.0000000e+00 1.0000000e+00 9.9999928e-01 1.7516155e-07 1.0000000e+00\n",
      " 7.2909950e-04 1.0000000e+00 1.1604608e-04 1.2712156e-03 9.9995291e-01\n",
      " 3.0098399e-04 1.0000000e+00 2.4236527e-03 3.8425245e-05 8.4297873e-02\n",
      " 1.5375892e-02 9.9977702e-01 9.9884230e-01 1.4470710e-02 1.1092478e-02\n",
      " 8.8763869e-01 2.8985145e-04 9.9996722e-01]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify your model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                320       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 386\n",
      "Trainable params: 386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's play with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Google Playground](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/playground-exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Number of Hidden Layers**\n",
    "\n",
    "*For many problems you can start with just one or two hidden layers it will work just fine. For more complex problems, you can gradually ramp up the number of hidden layers until your model starts to over fit. Very complex tasks, like image classification, will need dozens of layers.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Number of Neurons per layer**\n",
    "\n",
    "*The number of nuerons for the input and output layers are dependent on your data and the task. For hiddne layers, a common practice is to create a funnel with funnel with fewer and fewer neurons per layer.*\n",
    "\n",
    "*In general, you will get more bang for your buck by adding on more layers than adding more neurons.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[Activation Functions](https://towardsdatascience.com/exploring-activation-functions-for-neural-networks-73498da59b02)**\n",
    "    - Linear\n",
    "    - Sigmoid\n",
    "    - Softmax\n",
    "    - Tanh\n",
    "    - ReLu\n",
    "    - elu\n",
    "    \n",
    "*In most cases you can use the ReLu activation function (or one of its variants) in the hidden layers. For the output layer, the softmax activation function is generally good for multiclass problems and the sigmouid function for binary classificatin problems. For regression tasks, you can simply use no activation function at all*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Selecting an optimizer](https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/)\n",
    "    - Adam\n",
    "    - SGD\n",
    "    - RMSprop\n",
    "    - Adagrad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Learning Rate**\n",
    "\n",
    "*If you set it too low, training will eventually converge, but it will do so slowly.*\n",
    "*If you set it too high, it might acutally diverge.*\n",
    "*If you set it slightly too high, it will converge at first but miss the local optima.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Regularization** \n",
    "    - L1 and L2\n",
    "    - Dropout\n",
    "    \n",
    "    *the most popular techniqure for deep neural networks. It is a fairly simple algorithm where at every training step, every neuron has a probability fo being teporarily \"droppedout,\" meaning it will be completely ignored during this traing step, but it may be active during the next step.*\n",
    "    \n",
    "    - [Early Stopping](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/)\n",
    "    \n",
    "    *Just interrupt training whne its performance on the validation set starts dropping*\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Paper on selecting hyperparameters](https://arxiv.org/pdf/1206.5533v2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Model with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import  Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first network with Keras\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "Models in Keras are defined as a sequence of layers.\n",
    "\n",
    "We create a Sequential model and add layers one at a time until we are happy with our network topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential()\n",
    "\n",
    "# Add a dropout layer for input layer\n",
    "network.add(Dropout(0.2, input_shape=(n_cols,)))\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(Dense(units=16, activation='relu'))\n",
    "# Add a dropout layer for previous hidden layer\n",
    "network.add(Dropout(0.25))\n",
    "# Add fully connected layer with a ReLU activation function and L2 regularization\n",
    "network.add(Dense(units=16, kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n",
    "#Final Layer\n",
    "network.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Using GridSearchCV to tune Neural Networks](https://chrisalbon.com/deep_learning/keras/tuning_neural_network_hyperparameters/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras Implementation of optimizers](https://keras.io/optimizers/)\n",
    "\n",
    "[Impact of Learning Rate on MOdel Performance](https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 711 samples, validate on 178 samples\n",
      "Epoch 1/15\n",
      " - 0s - loss: 5.2092 - acc: 0.3783 - val_loss: 4.0835 - val_acc: 0.3876\n",
      "Epoch 2/15\n",
      " - 0s - loss: 4.3181 - acc: 0.3812 - val_loss: 3.2670 - val_acc: 0.3876\n",
      "Epoch 3/15\n",
      " - 0s - loss: 3.4687 - acc: 0.3769 - val_loss: 2.4651 - val_acc: 0.3876\n",
      "Epoch 4/15\n",
      " - 0s - loss: 2.8286 - acc: 0.3910 - val_loss: 1.7040 - val_acc: 0.3876\n",
      "Epoch 5/15\n",
      " - 0s - loss: 2.7114 - acc: 0.3840 - val_loss: 1.1238 - val_acc: 0.3989\n",
      "Epoch 6/15\n",
      " - 0s - loss: 2.1990 - acc: 0.3910 - val_loss: 1.0130 - val_acc: 0.4551\n",
      "Epoch 7/15\n",
      " - 0s - loss: 1.9435 - acc: 0.4909 - val_loss: 0.8226 - val_acc: 0.6742\n",
      "Epoch 8/15\n",
      " - 0s - loss: 1.7052 - acc: 0.5007 - val_loss: 0.8174 - val_acc: 0.6067\n",
      "Epoch 9/15\n",
      " - 0s - loss: 1.9253 - acc: 0.5021 - val_loss: 0.7943 - val_acc: 0.6629\n",
      "Epoch 10/15\n",
      " - 0s - loss: 1.6788 - acc: 0.5331 - val_loss: 0.7756 - val_acc: 0.6910\n",
      "Epoch 11/15\n",
      " - 0s - loss: 1.6331 - acc: 0.4923 - val_loss: 0.7688 - val_acc: 0.7135\n",
      "Epoch 12/15\n",
      " - 0s - loss: 1.6171 - acc: 0.5485 - val_loss: 0.7767 - val_acc: 0.7079\n",
      "Epoch 13/15\n",
      " - 0s - loss: 1.6075 - acc: 0.5387 - val_loss: 0.7805 - val_acc: 0.7135\n",
      "Epoch 14/15\n",
      " - 0s - loss: 1.3840 - acc: 0.5696 - val_loss: 0.8022 - val_acc: 0.6966\n",
      "Epoch 15/15\n",
      " - 0s - loss: 1.4174 - acc: 0.5513 - val_loss: 0.8105 - val_acc: 0.6910\n"
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "history = network.fit(X_train, # Features\n",
    "                      y_train, # Target\n",
    "                      epochs=15, # Number of epochs\n",
    "                      verbose=2, # Some output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(X_test, y_test)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 38us/step\n"
     ]
    }
   ],
   "source": [
    "score = network.evaluate(X_test, y_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 69.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (network.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predictions = network.predict(X_test)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/deep_learning/keras/visualize_loss_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training and test accuracy histories\n",
    "training_accuracy = history.history['acc']\n",
    "test_accuracy = history.history['val_acc']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_accuracy) + 1)\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy, 'b-')\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/deep_learning/keras/visualize_performance_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_6_input to have shape (9,) but got array with shape (20,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-4159432e3081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# calculate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# round predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrounded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_6_input to have shape (9,) but got array with shape (20,)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model.predict(X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources \n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/\n",
    "    \n",
    "http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/\n",
    "\n",
    "https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/deep_learning/keras/visualize_neural_network_architecture/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
